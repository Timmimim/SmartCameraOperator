# SmartCameraOperator
Practical Assignment complementing the Computer Vision lecture held by Prof. Dr. Risse at WWU Münster. 
The Practical is further supervised by Sören Klemm.

### Goals
This project aims to create a smart detector for horse-rider-pairs in videos.
The detector must find all rider pairs in a scene, and extract the accompanying Regions of Interest (RoI).
RoIs are used to zoom in on the riders.

### Our approach
Our team decided to tackle the assignment using the Python, C and C++ programming languages, 
as well as the [Darknet](https://github.com/pjreddie/darknet "You only click once. ;-)") framework for Convolutional Neural Networks (CNNs)
and the YOLOv3 and tinyYOLOv3 network architectures.

For multiple data management tasks we created a number of Python3 scripts.  
We also compiled the Darknet framework on a Ubuntu Linux computer with a relatively low-end CUDA-able nVidia Graphics Card.

##

### Project Structure
The Project is split into different stages ('Iterations'), and a number of different but related problems.
The status of our project at any given stage is marked by a tagged commit.
Underlying data is not supplied here, as it would not be exactly reasonable, and also the volume far surpasses GitHub size limitations.
Data was supplied in the form of videos, as well as images extracted from them.


#### Iteration 1
Iteration 1 has no tag, as there was no code generated at that stage. It consisted of labelling only.
The labels were generated by hand by the participants of this practical, and arranged into a database by the supervisors.
Labelled images and the labels assigned to them were supplied later, the latter as a `.csv` file, as well as the original videos.

#### Iteration 2

At the basis of this step lies a self-trained Darknet-based YOLOv3 detector. 
Training was initialised from the 

*Iteration 2* was solved in multiple steps:

The `code/` directory contains two Python3 scripts. They manage our training data for the detector
`readCSVAndYolofy.py` reads the hard-coded target `'rimondo_filtered.csv'`, which contains the aforementioned labels.
The script creates objects for each user generating labels, each image they labelled, and each label set. 
Labels are then saved to uniquely named `.txt` files, and a copy of the corresponding image is saved alongside each file by the same name.
This forms the database used to train a *Machine Learning* based detector later. 
Our database spanned 105558 (highly redundant) images plus one label file each, amounting to 101.5GiB.    
`createYoloLearnList.py` creates two `.txt` files listing labelled images. 
The database created above is split into 90% training, and 10% validation data.   

Using this database, we trained the afforementioned YOLO detector, which we then used via the `detect_in_video.py` script, 
located in the `detection/` directory.
This script is written around the [YOLO3-4-Py][yolo34py-gpu] Python-wrapper for Darknet, as a simple command line tool.   
There are different settings available for the tool:

- 


#### Iteration 3
*ongoing*

##

##### Software and Technology used
![YOLOv3 and YOLO][yolo]
![Darknet][darknet]
![OpenCV][opencv]

[Darknet](https://github.com/pjreddie/darknet "Really super dark!"),
[YOLOv3](https://pjreddie.com/darknet/yolo/ "You only click once. ;-)"),
[Python 3.6^](https://www.python.org/ "Ni!!!"),
[YOLO3-4-Py][yolo34py-gpu]

##### Created by
Max Loch, Jacomo Krause und Timm Kühnel

##### Licence
GNU GPL v3


[http://www.bla.de/]: http://www.bla.de/

[yolo]: https://pjreddie.com/media/image/yologo_2.png "You only look once."
[darknet]: https://camo.githubusercontent.com/e69d4118b20a42de4e23b9549f9a6ec6dbbb0814/687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67 "So dark!!"
[opencv]: https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/OpenCV_Logo_with_text.png/195px-OpenCV_Logo_with_text.png "CV, but Open."
[yolo34py-gpu]: https://github.com/madhawav/YOLO3-4-Py "You only Python-wrap once. ;-)"